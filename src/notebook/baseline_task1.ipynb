{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from sentence_transformers import CrossEncoder\n",
    "import logging\n",
    "\n",
    "sub_s = os.sep.join(os.getcwd().split(os.sep)[:-1] + ['submodule', 'financerag'])\n",
    "sys.path.append(sub_s)\n",
    "\n",
    "from financerag.rerank import CrossEncoderReranker\n",
    "from financerag.retrieval import DenseRetrieval, SentenceTransformerEncoder\n",
    "from financerag.tasks import FinDER\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:financerag.common.loader:A Hugging Face repository is provided. This will override the data_folder, prefix, and *_file arguments.\n",
      "INFO:financerag.common.loader:Loading Corpus...\n",
      "INFO:financerag.common.loader:Loaded 13867 Documents.\n",
      "INFO:financerag.common.loader:Corpus Example: {'id': 'ADBE20230004', 'title': 'ADBE OVERVIEW', 'text': 'Adobe is a global technology company with a mission to change the world through personalized digital experiences. For over four decades, Adobe’s innovations have transformed how individuals, teams, businesses, enterprises, institutions, and governments engage and interact across all types of media. Our products, services and solutions are used around the world to imagine, create, manage, deliver, measure, optimize and engage with content across surfaces and fuel digital experiences. We have a diverse user base that includes consumers, communicators, creative professionals, developers, students, small and medium businesses and enterprises. We are also empowering creators by putting the power of artificial intelligence (“AI”) in their hands, and doing so in ways we believe are responsible. Our products and services help unleash creativity, accelerate document productivity and power businesses in a digital world.'}\n",
      "INFO:financerag.common.loader:Loading Queries...\n",
      "INFO:financerag.common.loader:Loaded 216 Queries.\n",
      "INFO:financerag.common.loader:Query Example: {'id': 'q00001', 'text': 'What are the service and product offerings from Microsoft'}\n"
     ]
    }
   ],
   "source": [
    "finder_task = FinDER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: intfloat/e5-large-v2\n",
      "c:\\Users\\tenet\\anaconda3\\envs\\financeRAG_acm\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tenet\\.cache\\huggingface\\hub\\models--intfloat--e5-large-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "encoder_model = SentenceTransformerEncoder(\n",
    "    model_name_or_path='intfloat/e5-large-v2',\n",
    "    query_prompt='query: ',\n",
    "    doc_prompt='passage: ',\n",
    ")\n",
    "\n",
    "retrieval_model = DenseRetrieval(\n",
    "    model=encoder_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.retrieval.dense:Encoding queries...\n",
      "Batches: 100%|██████████| 4/4 [00:01<00:00,  3.69it/s]\n",
      "INFO:financerag.retrieval.dense:Sorting corpus by document length...\n",
      "INFO:financerag.retrieval.dense:Encoding corpus in batches... This may take a while.\n",
      "INFO:financerag.retrieval.dense:Encoding batch 1/1...\n",
      "Batches: 100%|██████████| 217/217 [07:31<00:00,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "retrieval_model = DenseRetrieval(\n",
    "    model=encoder_model\n",
    ")\n",
    "\n",
    "retrieval_result = finder_task.retrieve(\n",
    "    retriever=retrieval_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved results for 216 queries. Here's an example of the top 5 documents for the first query:\n",
      "\n",
      "Query ID: q00001\n",
      "  Document 1: Document ID = MSFT20230966, Score = 0.8739960789680481\n",
      "  Document 2: Document ID = MSFT20230216, Score = 0.8645689487457275\n",
      "  Document 3: Document ID = MSFT20230015, Score = 0.859443724155426\n",
      "  Document 4: Document ID = MSFT20230254, Score = 0.8580108284950256\n",
      "  Document 5: Document ID = MSFT20230155, Score = 0.8534095287322998\n"
     ]
    }
   ],
   "source": [
    "# Print a portion of the retrieval results to verify the output.\n",
    "print(f\"Retrieved results for {len(retrieval_result)} queries. Here's an example of the top 5 documents for the first query:\")\n",
    "\n",
    "for q_id, result in retrieval_result.items():\n",
    "    print(f\"\\nQuery ID: {q_id}\")\n",
    "    # Sort the result to print the top 5 document ID and its score\n",
    "    sorted_results = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i, (doc_id, score) in enumerate(sorted_results[:5]):\n",
    "        print(f\"  Document {i + 1}: Document ID = {doc_id}, Score = {score}\")\n",
    "\n",
    "    break  # Only show the first query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tenet\\anaconda3\\envs\\financeRAG_acm\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tenet\\.cache\\huggingface\\hub\\models--cross-encoder--ms-marco-MiniLM-L-12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "INFO:sentence_transformers.cross_encoder.CrossEncoder:Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "reranker = CrossEncoderReranker(\n",
    "    model=CrossEncoder('cross-encoder/ms-marco-MiniLM-L-12-v2')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.rerank.cross_encoder:Starting To Rerank Top-100....\n",
      "Batches: 100%|██████████| 675/675 [02:31<00:00,  4.46it/s]\n"
     ]
    }
   ],
   "source": [
    "reranking_result = finder_task.rerank(\n",
    "    reranker=reranker,\n",
    "    results=retrieval_result,\n",
    "    top_k=100,  # Rerank the top 100 documents\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reranking results for 216 queries. Here's an example of the top 5 documents for the first query:\n",
      "\n",
      "Query ID: q00001\n",
      "  Document 1: Document ID = MSFT20230254, Score = 6.622737884521484\n",
      "  Document 2: Document ID = MSFT20230233, Score = 6.088945388793945\n",
      "  Document 3: Document ID = MSFT20230230, Score = 5.898367881774902\n",
      "  Document 4: Document ID = MSFT20230236, Score = 5.747088432312012\n",
      "  Document 5: Document ID = MSFT20230216, Score = 5.488572120666504\n"
     ]
    }
   ],
   "source": [
    "# Print a portion of the reranking results to verify the output.\n",
    "print(f\"Reranking results for {len(reranking_result)} queries. Here's an example of the top 5 documents for the first query:\")\n",
    "\n",
    "for q_id, result in reranking_result.items():\n",
    "    print(f\"\\nQuery ID: {q_id}\")\n",
    "    # Sort the result to print the top 5 document ID and its score\n",
    "    sorted_results = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for i, (doc_id, score) in enumerate(sorted_results[:5]):\n",
    "        print(f\"  Document {i + 1}: Document ID = {doc_id}, Score = {score}\")\n",
    "\n",
    "    break  # Only show the first query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.tasks.BaseTask:Output directory set to: ./results\\FinDER\n",
      "INFO:financerag.tasks.BaseTask:Saving top 10 results to CSV file: ./results\\FinDER\\results.csv\n",
      "INFO:financerag.tasks.BaseTask:Writing header ['query_id', 'corpus_id'] to CSV.\n",
      "INFO:financerag.tasks.BaseTask:Top 10 results saved successfully to ./results\\FinDER\\results.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results have been saved to ./results/FinDER/results.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Save results\n",
    "# -------------------\n",
    "# Save the results to the specified output directory as a CSV file.\n",
    "output_dir = './results'\n",
    "finder_task.save_results(output_dir=output_dir)\n",
    "\n",
    "# Confirm the results have been saved.\n",
    "print(f\"Results have been saved to {output_dir}/FinDER/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tenet\\AppData\\Local\\Temp\\ipykernel_5876\\50549677.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  qrels_dict = df.groupby('query_id').apply(lambda x: dict(zip(x['corpus_id'], x['score']))).to_dict()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from financerag.tasks import FinDER\n",
    "df = pd.read_csv('../files/icaif-24-finance-rag-challenge/FinDER_qrels.tsv', sep='\\t')\n",
    "qrels_dict = df.groupby('query_id').apply(lambda x: dict(zip(x['corpus_id'], x['score']))).to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:financerag.tasks.BaseTask:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:NDCG@1: 0.2500\n",
      "INFO:financerag.tasks.BaseTask:NDCG@5: 0.3363\n",
      "INFO:financerag.tasks.BaseTask:NDCG@10: 0.3701\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:MAP@1: 0.2188\n",
      "INFO:financerag.tasks.BaseTask:MAP@5: 0.3051\n",
      "INFO:financerag.tasks.BaseTask:MAP@10: 0.3217\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:Recall@1: 0.2188\n",
      "INFO:financerag.tasks.BaseTask:Recall@5: 0.3969\n",
      "INFO:financerag.tasks.BaseTask:Recall@10: 0.4865\n",
      "INFO:financerag.tasks.BaseTask:\n",
      "\n",
      "INFO:financerag.tasks.BaseTask:P@1: 0.2500\n",
      "INFO:financerag.tasks.BaseTask:P@5: 0.1125\n",
      "INFO:financerag.tasks.BaseTask:P@10: 0.0719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'NDCG@1': 0.25, 'NDCG@5': 0.3363, 'NDCG@10': 0.37007},\n",
       " {'MAP@1': 0.21875, 'MAP@5': 0.30514, 'MAP@10': 0.3217},\n",
       " {'Recall@1': 0.21875, 'Recall@5': 0.39687, 'Recall@10': 0.48646},\n",
       " {'P@1': 0.25, 'P@5': 0.1125, 'P@10': 0.07188})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder_task.evaluate(qrels_dict, reranking_result, [1, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financeRAG_acm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
